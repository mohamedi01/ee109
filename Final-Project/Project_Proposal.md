# Project Proposal: FPGA-Accelerated Audio-to-NLP Engine
## By: William Briger, Chris Gutierrez, & Mohamad Ismail

## Introduction: 
We plan to accelerate the front-end of audio-driven applications. Using raw microphones samples, we will complete speech recognition, speech-to-text processing, and then apply lightweight Nautral-Langauge Processing (NLP). The primary goal of this project will be to effectively accelerate the audio processing and the light weight neural network, to produce keyword spotting, topic segmentation, or even meeting-minutes/ conversation summaries. However, there also exist many potential extensions that to expand on the applications of the low-latency speech-to-text processing (e.g, audio to on-device sign-langauge).

## Why an FPGA:
An FPGA is relevant for this application because of the Audio Digitial Signal Processing and Neural Network/ Transformer inference. Both of these core processes are  stream-ortiented processes with tight latency goals. To complete these live requires a pipelined and deterministic datapath that FPGAs can complete very efficiently. 

## Literature Survey:

## Project Description:

## Measure:

## Planning:

## Other Notes:

 
